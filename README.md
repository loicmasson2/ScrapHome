# Roadmap

1. Get more infos for home -> Done
2. Store them in a big file -> Done
3. Switch from file storage to use PostgreSQL
4. Write simple fastapi to serve the data, with pagination, sorting
5. Write simple vue front to call fastapi endpoints
   6. Have search, pagination, sorting and a map
7. Train simple random forest for best home

FROM docker images --digests | grep python
FROM python:3.12-slim@sha256:123229cfb27c384ee1fcc15aec660ad280a09121b7893377e80ae1b2e72cf942


# Organisation

## Crawler 
In extract.py I manualy enter the 1st page with filters I picked
e.g. page = requests.get("https://www.etuovi.com/myytavat-asunnot/helsinki?haku=M2054709531&sivu=1")

Then extract.py will extract a light amount of data:
- link
- summary
- price
- year

Once I have that, I can use extract_more.py.
Thanks to collecting all the links in the previous steps I can now loop over it.
While looping I can collect more details, and all the images.
For now the additional details are:
- size
- geolocation
- list of images

### Note on geolocation and list of images
Those infos are not available when using requests since they are generated by JS. ( looks like React)
In this case I have two options:
- use something like Puppeteer to have a browser and let is do its job
  - I used that in the past, and it is quite heavy thing to add
- cheat :)
  - I noticed that all the redux state is available
  - which contains the informations I am interested

## Analysis
I want to use random forest to do a data analysis on what is a good deal vs bad deal.

## Backend
Will use FastApi to have a layer on top of DB to serve a frontend
https://testdriven.io/blog/fastapi-docker-traefik/